Provider/Key,Models,Strengths for Academic Advising,Pricing (API),Free Credits / Tier Information,Throughput & Limits,Customization (Embeddings/RAG)
OpenAI,"GPT-4o; GPT-4o-mini; GPT-4.1; GPT-4.1 mini; GPT-4.1 nano; o3, o4-mini","Strong multimodal support (text, images, vision), huge context (up to 128K tokens), function calling",GPT-4o: ~$5.00/1M input + ~$20.00/1M output; GPT-4o mini: ~$0.60/1M input + ~$2.40/1M output. Fine-tuning and other tools have separate costs.,ChatGPT interface free for casual use; API newcomers get ~$10–20 credits.,"Mini: ~200K TPM, ~3-5K RPM; full model higher throughput and enterprise options.",Supports custom embeddings and RAG via its API and tools like Assistants API.
Anthropic,Claude 3.5 Sonnet; Claude 3.7 Sonnet; Claude 4/Opus; Claude Haiku 3.5,"Very large context windows (200K+ tokens), high reasoning alignment, safe outputs",Claude 3.5 Sonnet & Claude 3.7 Sonnet: ~$3/1M input + ~$15/1M output; Claude 4/Opus: ~$15/1M input + ~$75/1M output. Batch processing and tool use have separate pricing.,"Free access on Claude.ai web with limited usage; API trial. Pro plan $17/mo (individual), Teams higher usage tiers.","API rate ~5 requests/min free; paid tiers scale to dozens/hundreds RPM, hundreds TPS.",Supports custom embeddings and RAG; can be integrated with external embedding models.
Google / Vertex AI,Gemini 1.5 Pro; Gemini 1.5 Flash; Gemini 2.0; Flash Lite; Imagen 3; Gemini Embedding,"Multimodal across text, image, video, audio; seamless embedding/RAG support in Google ecosystem; massive 1M+ context in some variants","Gemini 1.5 Pro: ~$1.25-$2.50/1M input, $10-$15/1M output; Flash/Lite significantly cheaper (e.g., Flash-Lite ~$0.10/1M input, $0.40/1M output). Image generation and video have separate pricing.",New Google Cloud customers get $300 in free credits; free tier up to ~1M tokens/day (depending on account).,Scales with GSUs; enterprise scaling; some versions gated to previous usage accounts.,Strong support for custom embeddings and RAG within the Google Cloud ecosystem.
Meta / Open-source Llama 3,"Llama 3 (8B, 70B or larger)","Fully open-source, very low cost (can self-host), large context (128K+), perfect for offline or privacy-sensitive academic setups",Self-hosted at near zero token costs (just infrastructure); hosted APIs range ~$0.10-$0.90/1M output (8B/70B).,Free to download and use locally; hosted APIs may offer limited free tiers.,Depends on your infrastructure—can support thousands TPS if scaled.,Fully customizable for embeddings and RAG due to its open-source nature.
DeepSeek,DeepSeek-R1; DeepSeek-V3,"Open-weight models, efficient inference, cost-effective RAG; competitive reasoning in benchmarks","DeepSeek-R1: ~$0.45-$1.00/1M input, ~$2.15-$3.00/1M output; DeepSeek-V3: ~$0.27-$0.38/1M input, ~$0.88-$1.10/1M output.",Free unlimited usage for web app; API pay-as-you-go; no startup credits.,Run by DeepSeek; likely moderate-scale usage limits; open weights available for self-hosting.,DeepSeek-R1 features an adaptive embedding framework for RAG; supports custom embeddings.
xAI / Groq,Grok-3 Preview,"Fast inference, multimodal, lower latency; good for interactive advising interfaces",~$3/1M input + ~$15/1M output.,Free preview access with limited volume; paid tiers scale usage.,Very high TPS (e.g. ultra-fast GPU). Scalable via Groq infrastructure.,Supports RAG; custom embeddings can be integrated.
Together AI,Llama 3.1/3.3; Mistral Large; Qwen 3; various open-source models,"Large model variety, embeddings support, fine-tunability, cost-efficient open weights",Llama/Larger: ~$0.03-$0.80/1M input / ~$0.05-$0.80/1M output depending on model. Hardware and storage pricing also available for dedicated endpoints.,Sign-up free credit ~$1; free tier with rate/token limits (~60K tokens/min).,High concurrency; scale similar to cloud providers.,"Offers embeddings support and fine-tunability, making it suitable for custom RAG implementations."
DeepInfra,Llama 3.1 405B; Qwen2.5 72B; DeepSeek V3; Gemma 3; Phi,"Large-scale hosting options, vision support, long context; very cost-effective on large models",Llama 3.1 405B: ~$0.80/M combined; Qwen2.5 72B: ~$0.12 input / ~$0.39 output per 1M tokens. Pricing varies significantly by model.,Free signup credit ~$1.80; moderate usage limits (~200 concurrent requests).,Good for heavy RAG loads; strong throughput on hosted infra.,Provides various embedding models and supports RAG integrations.
OpenRouter,"Aggregates Llama, Claude, Gemini, Grok, Qwen, etc.",Unified API across multiple models/providers; dynamic routing for cost/latency balance,"Varies: uses provider rates; often lower pricing via bulk credits or model selection. Some models (e.g., Qwen3 Coder) are free.","Free tier includes access to some models (Gemma, Gemma-like) up to ~1K requests/day, 20 RPM.",Unified throughput—provider dependent; failover routing adds resilience.,Can work with custom embeddings and RAG by leveraging the underlying providers' capabilities.